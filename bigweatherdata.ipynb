{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b090cff3-4cc4-4600-8bb1-584dc64bd244",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Point the executor to the same Python interpreter the driver is using\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "91120315-234b-44e0-a9f4-3da59f91559e",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"HDFS_CSV_Test\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3cd82abd-3012-47e4-9a7d-f9312fd004b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_csv_path = \"hdfs://localhost:9000/weather_data//weatherbigdata.csv\"\n",
    "streaming_dir = \"hdfs://localhost:9000/streaming_weather/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3a4c5a6c-8031-4ebe-a735-56806cab7148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+----+----+----+----+--------+---------+---------+-----------+-----------+------------------+\n",
      "|         ID|      DATE|TMAX|TMIN|EVAP|PRCP|Latitude|Longitude|Elevation|TMAX_actual|TMIN_actual|            TRANGE|\n",
      "+-----------+----------+----+----+----+----+--------+---------+---------+-----------+-----------+------------------+\n",
      "|USR0000AGOP|  3/7/2011| -28|-200|NULL|NULL| 64.2381|-145.2669|    463.3|       -2.8|      -20.0|              17.2|\n",
      "|USC00201675| 9/26/2012| 200| 100|NULL|   0| 41.9622| -84.9925|    299.9|       20.0|       10.0|              10.0|\n",
      "|USC00389039| 12/3/2000|  33| -11|NULL|   0|    33.9| -80.5206|     76.2|        3.3|       -1.1|               4.4|\n",
      "|USC00230657| 5/10/2007| 267| 139|NULL|   3| 37.0539| -93.5756|    399.3|       26.7|       13.9|12.799999999999999|\n",
      "|USC00206510|  8/2/2018| 267| 156|NULL|  28| 45.3614| -84.9511|    228.0|       26.7|       15.6|              11.1|\n",
      "|USC00236045| 4/16/2008| 150|   6|NULL|   0| 36.5869| -89.5325|     92.0|       15.0|        0.6|              14.4|\n",
      "|USC00108535| 7/11/2012| 356|  94|NULL|   0| 42.6514|-111.5833|   1780.6|       35.6|        9.4|26.200000000000003|\n",
      "|USC00445150|  1/5/1997| 239|  39|NULL|   0| 38.3683| -78.2503|    175.9|       23.9|        3.9|              20.0|\n",
      "|USW00013728|  2/8/2021| 106| -55|NULL|   0| 36.5728|  -79.335|    168.2|       10.6|       -5.5|              16.1|\n",
      "|USC00396170| 2/19/1998|  33|   0|NULL|   0| 44.4419|-100.4172|    506.9|        3.3|        0.0|               3.3|\n",
      "|USC00352440| 6/21/2012| 311|  61|NULL|NULL| 45.4539|-121.1303|    405.4|       31.1|        6.1|              25.0|\n",
      "|USC00326155|  7/3/1995| 294| 111|NULL|  20| 46.3747|-102.3211|    739.4|       29.4|       11.1|18.299999999999997|\n",
      "|USW00013866| 12/1/2002|   6| -44|NULL|   3| 38.3794| -81.5911|    278.0|        0.6|       -4.4|               5.0|\n",
      "|USW00054780|10/17/2001| 172| 100|NULL|   0| 41.0731| -71.9236|      2.1|       17.2|       10.0| 7.199999999999999|\n",
      "|USC00306085| 1/21/2013|  61| -94|NULL|   3| 42.5117| -75.5197|    301.4|        6.1|       -9.4|              15.5|\n",
      "|USC00249023|11/19/1993|  28|-117|NULL|   0| 46.0306|-110.5056|   1787.7|        2.8|      -11.7|              14.5|\n",
      "|USS0009F04S|  9/6/1996| 155| -47|NULL|   0|    43.7|  -109.67|   2667.0|       15.5|       -4.7|              20.2|\n",
      "|USC00424968|12/14/2004| 178|  -6|NULL|   0| 37.2008|-113.2686|    973.5|       17.8|       -0.6|18.400000000000002|\n",
      "|USS0007E06S|  1/4/1998| -50|-125|NULL|   0|   44.16|  -107.13|   2889.5|       -5.0|      -12.5|               7.5|\n",
      "|USC00324203| 6/23/2009| 278| 194|NULL|   0| 47.4389| -97.0664|    277.4|       27.8|       19.4| 8.400000000000002|\n",
      "+-----------+----------+----+----+----+----+--------+---------+---------+-----------+-----------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import *\n",
    "df = spark.read.csv(original_csv_path, header=True, inferSchema=True)\n",
    " # Step 2.1: Drop rows with null temperature values\n",
    "clean_df = df.na.drop(subset=[\"TMAX\", \"TMIN\"])\n",
    "\n",
    "# Step 2.2: Transform temperature to actual degrees Celsius and add a 'range' column\n",
    "transformed_df = clean_df.withColumn(\"TMAX_actual\", col(\"TMAX\") / 10.0) \\\n",
    "                   .withColumn(\"TMIN_actual\", col(\"TMIN\") / 10.0) \\\n",
    "                   .withColumn(\"TRANGE\", col(\"TMAX_actual\") - col(\"TMIN_actual\"))\n",
    "\n",
    "# Step 2.3: Add a data quality filter to ensure TMAX is greater than or equal to TMIN\n",
    "validated_df = transformed_df.filter(col(\"TMAX_actual\") >= col(\"TMIN_actual\"))\n",
    "validated_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "65ae9fd9-e0e6-4845-b206-17f9e142740f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "pandas_df = validated_df.sample(fraction=0.01).toPandas()  # only 1% of data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ec63c8dc-22fe-4ffd-bd76-c4e5d9b3ba40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>DATE</th>\n",
       "      <th>TMAX</th>\n",
       "      <th>TMIN</th>\n",
       "      <th>EVAP</th>\n",
       "      <th>PRCP</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Elevation</th>\n",
       "      <th>TMAX_actual</th>\n",
       "      <th>TMIN_actual</th>\n",
       "      <th>TRANGE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>USC00104670</td>\n",
       "      <td>6/12/1993</td>\n",
       "      <td>200</td>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.7325</td>\n",
       "      <td>-114.5192</td>\n",
       "      <td>1140.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>17.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>USC00466284</td>\n",
       "      <td>3/31/2012</td>\n",
       "      <td>217</td>\n",
       "      <td>44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48.0</td>\n",
       "      <td>38.1878</td>\n",
       "      <td>-80.8483</td>\n",
       "      <td>595.3</td>\n",
       "      <td>21.7</td>\n",
       "      <td>4.4</td>\n",
       "      <td>17.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>USC00249187</td>\n",
       "      <td>4/2/2011</td>\n",
       "      <td>56</td>\n",
       "      <td>-6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>130.0</td>\n",
       "      <td>48.9514</td>\n",
       "      <td>-115.6267</td>\n",
       "      <td>940.3</td>\n",
       "      <td>5.6</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>6.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>USR0000ALOS</td>\n",
       "      <td>3/17/2021</td>\n",
       "      <td>-111</td>\n",
       "      <td>-239</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66.0425</td>\n",
       "      <td>-147.9714</td>\n",
       "      <td>213.4</td>\n",
       "      <td>-11.1</td>\n",
       "      <td>-23.9</td>\n",
       "      <td>12.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>USR0000CDOW</td>\n",
       "      <td>12/13/1997</td>\n",
       "      <td>33</td>\n",
       "      <td>-150</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.6269</td>\n",
       "      <td>-106.4517</td>\n",
       "      <td>2742.6</td>\n",
       "      <td>3.3</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>18.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID        DATE  TMAX  TMIN  EVAP   PRCP  Latitude  Longitude  \\\n",
       "0  USC00104670   6/12/1993   200    28   NaN    0.0   42.7325  -114.5192   \n",
       "1  USC00466284   3/31/2012   217    44   NaN   48.0   38.1878   -80.8483   \n",
       "2  USC00249187    4/2/2011    56    -6   NaN  130.0   48.9514  -115.6267   \n",
       "3  USR0000ALOS   3/17/2021  -111  -239   NaN    NaN   66.0425  -147.9714   \n",
       "4  USR0000CDOW  12/13/1997    33  -150   NaN    NaN   39.6269  -106.4517   \n",
       "\n",
       "   Elevation  TMAX_actual  TMIN_actual  TRANGE  \n",
       "0     1140.0         20.0          2.8    17.2  \n",
       "1      595.3         21.7          4.4    17.3  \n",
       "2      940.3          5.6         -0.6     6.2  \n",
       "3      213.4        -11.1        -23.9    12.8  \n",
       "4     2742.6          3.3        -15.0    18.3  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bb5e253f-978e-452e-a7c1-be67d6773d84",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1 written to HDFS\n",
      "+-----------+----------+----+----+----+-----+--------+---------+---------+-----------+-----------+------------------+\n",
      "|         ID|      DATE|TMAX|TMIN|EVAP| PRCP|Latitude|Longitude|Elevation|TMAX_actual|TMIN_actual|            TRANGE|\n",
      "+-----------+----------+----+----+----+-----+--------+---------+---------+-----------+-----------+------------------+\n",
      "|USC00104670| 6/12/1993| 200|  28| NaN|  0.0| 42.7325|-114.5192|   1140.0|       20.0|        2.8|              17.2|\n",
      "|USC00466284| 3/31/2012| 217|  44| NaN| 48.0| 38.1878| -80.8483|    595.3|       21.7|        4.4|17.299999999999997|\n",
      "|USC00249187|  4/2/2011|  56|  -6| NaN|130.0| 48.9514|-115.6267|    940.3|        5.6|       -0.6| 6.199999999999999|\n",
      "|USR0000ALOS| 3/17/2021|-111|-239| NaN|  NaN| 66.0425|-147.9714|    213.4|      -11.1|      -23.9|12.799999999999999|\n",
      "|USR0000CDOW|12/13/1997|  33|-150| NaN|  NaN| 39.6269|-106.4517|   2742.6|        3.3|      -15.0|              18.3|\n",
      "|USR0000MBIG| 3/15/1997|  22|-589| NaN|  NaN| 45.0733|-107.8886|   2218.9|        2.2|      -58.9|              61.1|\n",
      "|USR0000ANOR| 3/14/2006|-111|-300| NaN|  NaN| 66.8333|-154.3333|    243.8|      -11.1|      -30.0|              18.9|\n",
      "|USR0000ATEL|  3/4/2013| -44|-250| NaN|  NaN|   63.44|-153.3567|    198.1|       -4.4|      -25.0|              20.6|\n",
      "|USR0000IRAF| 2/24/2003|  -6|-139| NaN|  NaN| 42.5478|-113.2594|   1341.1|       -0.6|      -13.9|              13.3|\n",
      "|USR0000MPPH|12/15/2003|-100|-133| NaN|  NaN| 46.8353|-110.7175|   2509.1|      -10.0|      -13.3|3.3000000000000007|\n",
      "+-----------+----------+----+----+----+-----+--------+---------+---------+-----------+-----------+------------------+\n",
      "\n",
      "Batch 2 written to HDFS\n",
      "+-----------+----------+----+----+----+----+--------+---------+---------+-----------+-----------+------+\n",
      "|         ID|      DATE|TMAX|TMIN|EVAP|PRCP|Latitude|Longitude|Elevation|TMAX_actual|TMIN_actual|TRANGE|\n",
      "+-----------+----------+----+----+----+----+--------+---------+---------+-----------+-----------+------+\n",
      "|USR0000NSHY| 3/14/1999|  56| -72| NaN| NaN| 46.4658| -97.3161|    326.1|        5.6|       -7.2|  12.8|\n",
      "|USR0000ITRI| 10/3/2019| 144| -56| NaN| NaN| 42.8286|-116.5886|   1606.3|       14.4|       -5.6|  20.0|\n",
      "|USR0000MMOR|  4/5/2020| 128| -50| NaN| NaN|   45.89| -93.2697|    308.5|       12.8|       -5.0|  17.8|\n",
      "|USR0000APLE| 1/13/2004| 178| -50| NaN| NaN| 34.0933|-110.9333|   1539.2|       17.8|       -5.0|  22.8|\n",
      "|USR0000MLIT|12/11/1999|  72| -39| NaN| NaN| 47.8139|-109.0167|    944.9|        7.2|       -3.9|  11.1|\n",
      "|USR0000CCRO| 1/26/2000|  44| -33| NaN| NaN| 39.3528|-107.0931|   2530.8|        4.4|       -3.3|   7.7|\n",
      "|USR0000OHOY| 2/25/1997| 117| -33| NaN| NaN| 42.9764|-121.4219|   1659.6|       11.7|       -3.3|  15.0|\n",
      "|USR0000CHNM| 2/21/2000|  22| -28| NaN| NaN| 36.5625|-117.4736|   2097.0|        2.2|       -2.8|   5.0|\n",
      "|USR0000OFAL|11/18/2005|  94| -11| NaN| NaN| 44.2939|-119.0333|   1813.3|        9.4|       -1.1|  10.5|\n",
      "|USR0000IDIA| 4/23/2007| 100| -11| NaN| NaN| 42.8667|-111.2167|   2286.0|       10.0|       -1.1|  11.1|\n",
      "+-----------+----------+----+----+----+----+--------+---------+---------+-----------+-----------+------+\n",
      "\n",
      "Batch 3 written to HDFS\n",
      "+-----------+----------+----+----+----+----+--------+---------+---------+-----------+-----------+------------------+\n",
      "|         ID|      DATE|TMAX|TMIN|EVAP|PRCP|Latitude|Longitude|Elevation|TMAX_actual|TMIN_actual|            TRANGE|\n",
      "+-----------+----------+----+----+----+----+--------+---------+---------+-----------+-----------+------------------+\n",
      "|USR0000IPIN| 3/21/2018|  94|  -6| NaN| NaN|   44.25|  -116.18|   1341.1|        9.4|       -0.6|              10.0|\n",
      "|USR0000NWAT|12/23/2005|  72|   0| NaN| NaN| 47.7803|-103.2867|    659.9|        7.2|        0.0|               7.2|\n",
      "|USR0000MKLL| 11/5/2003| -44|-128| NaN| NaN| 47.9425|  -94.455|    412.1|       -4.4|      -12.8|               8.4|\n",
      "|USC00103108| 12/9/2007| -11|-122| NaN| NaN| 43.3428|  -114.79|   1543.8|       -1.1|      -12.2|              11.1|\n",
      "|USC00500247| 3/18/2001|  17|-122| NaN| NaN| 62.1925|-150.5033|    136.9|        1.7|      -12.2|13.899999999999999|\n",
      "|USR0000MCON|11/10/2018|  33| -61| NaN| NaN| 47.5361|-113.7172|   1122.9|        3.3|       -6.1| 9.399999999999999|\n",
      "|USR0000OBLU| 11/4/2013|  56| -61| NaN| NaN|   44.67|-117.9336|   1280.2|        5.6|       -6.1|              11.7|\n",
      "|USR0000OALL| 2/15/2004|  61| -61| NaN| NaN| 43.9247|-119.5944|   1621.5|        6.1|       -6.1|              12.2|\n",
      "|USR0000TLEW|  1/9/2017|  61| -44| NaN| NaN| 35.3817| -86.7658|    350.5|        6.1|       -4.4|              10.5|\n",
      "|USR0000NBLU|11/10/2000|   6| -39| NaN| NaN| 40.5017|-119.1217|   1392.9|        0.6|       -3.9|               4.5|\n",
      "+-----------+----------+----+----+----+----+--------+---------+---------+-----------+-----------+------------------+\n",
      "\n",
      "Batch 4 written to HDFS\n",
      "+-----------+----------+----+----+----+----+--------+---------+---------+-----------+-----------+------------------+\n",
      "|         ID|      DATE|TMAX|TMIN|EVAP|PRCP|Latitude|Longitude|Elevation|TMAX_actual|TMIN_actual|            TRANGE|\n",
      "+-----------+----------+----+----+----+----+--------+---------+---------+-----------+-----------+------------------+\n",
      "|USR0000IDER| 2/14/1994|  61| -33| NaN| NaN| 43.1744|-115.1517|   1691.6|        6.1|       -3.3| 9.399999999999999|\n",
      "|USR0000OMID| 3/28/2009|  44| -22| NaN| NaN| 45.5833|-121.5833|    792.5|        4.4|       -2.2|6.6000000000000005|\n",
      "|USR0000CDEV|  3/9/1997| 133| -22| NaN| NaN| 37.2269|-107.3047|   2243.3|       13.3|       -2.2|              15.5|\n",
      "|USR0000MWEG| 1/17/2004|  11| -17| NaN| NaN| 48.5106|-113.9942|    975.4|        1.1|       -1.7|               2.8|\n",
      "|USR0000NCOM| 1/28/2003|  78| -17| NaN| NaN| 39.3814| -116.175|   2008.6|        7.8|       -1.7|               9.5|\n",
      "|USR0000CBLD| 2/14/1996| 150| -17| NaN| NaN| 41.0547|-120.3375|   1711.5|       15.0|       -1.7|              16.7|\n",
      "|USR0000AKLA| 5/13/2002| 122| -11| NaN| NaN| 62.1472|-144.9281|    944.9|       12.2|       -1.1|13.299999999999999|\n",
      "|USR0000WBUR| 5/16/2003| 144| -11| NaN| NaN| 44.7853|-107.5347|   2360.1|       14.4|       -1.1|              15.5|\n",
      "|USR0000AMOS|11/18/1994|   0|-117| NaN| NaN| 35.0336|-113.8925|   1804.4|        0.0|      -11.7|              11.7|\n",
      "|USR0000IDEA|12/13/2005|  17|-100| NaN| NaN| 44.3256|-117.1678|   1088.1|        1.7|      -10.0|              11.7|\n",
      "+-----------+----------+----+----+----+----+--------+---------+---------+-----------+-----------+------------------+\n",
      "\n",
      "Batch 5 written to HDFS\n",
      "+-----------+----------+----+----+----+----+--------+---------+---------+-----------+-----------+------------------+\n",
      "|         ID|      DATE|TMAX|TMIN|EVAP|PRCP|Latitude|Longitude|Elevation|TMAX_actual|TMIN_actual|            TRANGE|\n",
      "+-----------+----------+----+----+----+----+--------+---------+---------+-----------+-----------+------------------+\n",
      "|USR0000CGUN|  2/3/1998|  50| -94| NaN| NaN| 40.2092|-106.3292|   2566.4|        5.0|       -9.4|              14.4|\n",
      "|USR0000IBON| 1/12/2008|   6| -89| NaN| NaN|  44.375|-114.5667|   1953.8|        0.6|       -8.9|               9.5|\n",
      "|USR0000IGOO| 2/17/2015|  94| -61| NaN| NaN|  42.095|-113.8958|   1725.2|        9.4|       -6.1|              15.5|\n",
      "|USR0000OLIG|  2/4/1992| 117| -50| NaN| NaN| 44.0833|-120.0981|   1280.2|       11.7|       -5.0|              16.7|\n",
      "|USR0000OBAD|12/22/2017|   0| -39| NaN| NaN|   44.03|   -120.4|   1731.3|        0.0|       -3.9|               3.9|\n",
      "|USR0000OFOS| 9/15/2017| 178| -39| NaN| NaN| 42.9736|-119.2461|   1524.0|       17.8|       -3.9|              21.7|\n",
      "|USR0000CBUL|  3/3/1993|  89| -22| NaN| NaN| 40.4808|-120.1139|   1339.6|        8.9|       -2.2|11.100000000000001|\n",
      "|USR0000CHEL|12/14/1997|  44| -17| NaN| NaN| 39.0717|-120.4217|   1597.2|        4.4|       -1.7|6.1000000000000005|\n",
      "|USR0000IMHO|11/30/2018|  44| -11| NaN| NaN| 43.0283|  -115.87|    914.4|        4.4|       -1.1|               5.5|\n",
      "|USR0000CMTZ|12/30/2014|  50| -11| NaN| NaN| 38.3894|-120.6511|    902.2|        5.0|       -1.1|               6.1|\n",
      "+-----------+----------+----+----+----+----+--------+---------+---------+-----------+-----------+------------------+\n",
      "\n",
      "Batch 6 written to HDFS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:KeyboardInterrupt while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Admin\\miniconda3\\envs\\bigdata\\lib\\site-packages\\py4j\\java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"C:\\Users\\Admin\\miniconda3\\envs\\bigdata\\lib\\site-packages\\py4j\\clientserver.py\", line 511, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "  File \"C:\\Users\\Admin\\miniconda3\\envs\\bigdata\\lib\\socket.py\", line 716, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m spark_batch_df\u001b[38;5;241m.\u001b[39mwrite\u001b[38;5;241m.\u001b[39mmode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mappend\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mcsv(batch_path, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBatch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_num\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m written to HDFS\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 19\u001b[0m \u001b[43mspark_batch_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Increment counters\u001b[39;00m\n\u001b[0;32m     21\u001b[0m rows_used \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m batch_size\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\bigdata\\lib\\site-packages\\pyspark\\sql\\dataframe.py:959\u001b[0m, in \u001b[0;36mDataFrame.show\u001b[1;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[0;32m    953\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PySparkTypeError(\n\u001b[0;32m    954\u001b[0m         error_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNOT_BOOL\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    955\u001b[0m         message_parameters\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvertical\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(vertical)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m},\n\u001b[0;32m    956\u001b[0m     )\n\u001b[0;32m    958\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(truncate, \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m truncate:\n\u001b[1;32m--> 959\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshowString\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvertical\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    960\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    961\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\bigdata\\lib\\site-packages\\py4j\\java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1314\u001b[0m args_command, temp_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_args(\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m-> 1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m get_return_value(\n\u001b[0;32m   1323\u001b[0m     answer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[0;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\bigdata\\lib\\site-packages\\py4j\\java_gateway.py:1038\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[1;34m(self, command, retry, binary)\u001b[0m\n\u001b[0;32m   1036\u001b[0m connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_connection()\n\u001b[0;32m   1037\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1038\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1039\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m binary:\n\u001b[0;32m   1040\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m response, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_connection_guard(connection)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\bigdata\\lib\\site-packages\\py4j\\clientserver.py:511\u001b[0m, in \u001b[0;36mClientServerConnection.send_command\u001b[1;34m(self, command)\u001b[0m\n\u001b[0;32m    509\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    510\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 511\u001b[0m         answer \u001b[38;5;241m=\u001b[39m smart_decode(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m    512\u001b[0m         logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnswer received: \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(answer))\n\u001b[0;32m    513\u001b[0m         \u001b[38;5;66;03m# Happens when a the other end is dead. There might be an empty\u001b[39;00m\n\u001b[0;32m    514\u001b[0m         \u001b[38;5;66;03m# answer before the socket raises an error.\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\bigdata\\lib\\socket.py:716\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    714\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    715\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 716\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    717\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    718\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import *\n",
    "batch_size = 10\n",
    "total_rows = len(pandas_df)\n",
    "rows_used = 0\n",
    "batch_num = 1\n",
    "while rows_used < total_rows:\n",
    "    # Select the next batch of rows\n",
    "    batch_df = pandas_df.iloc[rows_used:rows_used + batch_size]\n",
    "    \n",
    "    # Convert batch back to Spark DataFrame\n",
    "    spark_batch_df = spark.createDataFrame(batch_df)\n",
    "   \n",
    "    # Write batch to HDFS\n",
    "    batch_path = os.path.join(streaming_dir, f\"batch_{batch_num}\")\n",
    "    spark_batch_df.write.mode(\"append\").csv(batch_path, header=True)\n",
    "   \n",
    "    print(f\"Batch {batch_num} written to HDFS\")\n",
    "    spark_batch_df.show()\n",
    "    # Increment counters\n",
    "    rows_used += batch_size\n",
    "    batch_num += 1\n",
    "    \n",
    "    # Pause to simulate real-time arrival\n",
    "    time.sleep(2)  # 2 seconds between batches\n",
    "\n",
    "print(\"All batches streamed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c20ae9b-d457-4cc5-ad33-3ec38e48b604",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989fa0b6-7217-447b-b404-0a43d61daf32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269b5b38-442b-41ee-9d66-649061296cfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d0f3a6-111d-495b-8c4d-bc078994bfd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff63a39-1002-4b51-9d30-3789c1031781",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9cdbec-d553-4273-872f-f74e1df3f4e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa01e9c9-2c7d-49b0-9a26-78b0dfc92186",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
