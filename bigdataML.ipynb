{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f0f6df2-2753-492e-adbd-737033ab38a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Point the executor to the same Python interpreter the driver is using\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db43ae9-d2fe-48d4-af0d-4cf91eb5e2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"WeatherLinearRegression\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d1b519-0c29-4a4e-85bb-c3a85181a39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, to_date, dayofyear\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7e6e33-6900-4e77-be4f-a7a07ca06d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_csv_path = \"hdfs://localhost:9000/weather_data//weatherbigdata.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3df15f-17ef-4988-9cf8-385641e6fcba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(original_csv_path, header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce805a4-6be0-4243-a264-533b915f26c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2.1: Drop rows with null temperature values\n",
    "clean_df = df.na.drop(subset=[\"TMAX\", \"TMIN\"])\n",
    "\n",
    "# Step 2.2: Transform temperature to actual degrees Celsius and add a 'range' column\n",
    "transformed_df = clean_df.withColumn(\"TMAX_actual\", col(\"TMAX\") / 10.0) \\\n",
    "                   .withColumn(\"TMIN_actual\", col(\"TMIN\") / 10.0) \\\n",
    "                   .withColumn(\"TRANGE\", col(\"TMAX_actual\") - col(\"TMIN_actual\"))\n",
    "\n",
    "# Step 2.3: Add a data quality filter to ensure TMAX is greater than or equal to TMIN\n",
    "validated_df = transformed_df.filter(col(\"TMAX_actual\") >= col(\"TMIN_actual\"))\n",
    "selected_df = validated_df.select(\n",
    "    col(\"DATE\"),\n",
    "    col(\"Latitude\").cast(\"double\"),\n",
    "    col(\"Longitude\").cast(\"double\"),\n",
    "    col(\"Elevation\").cast(\"double\"),\n",
    "    col(\"TMAX_actual\").cast(\"double\")\n",
    ").na.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3014a8-7bc9-4e07-8699-ea58aef92cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280c9eb4-c254-4258-b680-34f6c2a66a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "featured_df = selected_df.withColumn(\"DayOfYear\", dayofyear(to_date(col(\"DATE\"), \"M/d/yyyy\")))\n",
    "feature_columns = [\"Latitude\", \"Longitude\", \"Elevation\", \"DayOfYear\"]\n",
    "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
    "final_df = assembler.transform(featured_df)\n",
    "final_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef475ee7-f1ba-4892-b61b-30d32b66c31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df = final_df.select(\"features\",col(\"TMAX_actual\").alias(\"label\"))\n",
    "model_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7164b94c-004b-4f7e-b2ef-3d29695b0b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "(training_data,test_data) = model_df.randomSplit([0.8,0.2], seed=42) #seed=42 fixes the randomsplit everytime i run this cell\n",
    "lr = LinearRegression(featuresCol=\"features\",labelCol=\"label\")\n",
    "model = lr.fit(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee23c8b6-d305-4114-b28a-62e56f61fd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c942f3-c77b-4852-8ce9-81040e6cbccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Predictions on test data:\")\n",
    "predictions.select(\"label\", \"prediction\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914d0a88-d2e0-400d-a394-9ede7df898f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Evaluate the Model\n",
    "evaluator_rmse = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "evaluator_r2 = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"r2\")\n",
    "\n",
    "rmse = evaluator_rmse.evaluate(predictions)\n",
    "r2 = evaluator_r2.evaluate(predictions)\n",
    "\n",
    "print(f\"Root Mean Squared Error (RMSE) on test data: {rmse}\")\n",
    "print(f\"R-squared (R2) on test data: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de666338-9426-4a77-9e48-81226f63807d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gradient-Boosted Tree (GBT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66442672-2ed1-4105-832d-78308f07606b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, month, dayofyear, to_date\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import GBTRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f754f66-b958-488b-be6c-14f18be2738f",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"WeatherLinearRegression\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.driver.memory\",\"8g\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87417908-58dd-442d-b945-8cb698b3334c",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_schema = StructType([\n",
    "    StructField(\"ID\", StringType(), True),\n",
    "    StructField(\"DATE\", StringType(), True),\n",
    "    StructField(\"TMAX\", FloatType(), True),\n",
    "    StructField(\"TMIN\", FloatType(), True),\n",
    "    StructField(\"EVAP\", FloatType(), True),\n",
    "    StructField(\"PRCP\", FloatType(), True),\n",
    "    StructField(\"Latitude\", FloatType(), True),\n",
    "    StructField(\"Longitude\", FloatType(), True),\n",
    "    StructField(\"Elevation\", FloatType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a168cd8-8636-494a-934d-acabedb517e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_csv_path = \"hdfs://localhost:9000/weather_data/weatherbigdata.csv\"\n",
    "df = spark.read \\\n",
    "    .schema(weather_schema) \\\n",
    "    .option(\"header\", True) \\\n",
    "    .csv(original_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22a3572-5b07-4b49-a6f5-677b5856407e",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = df \\\n",
    "    .withColumn(\"TMAX_actual\", col(\"TMAX\") / 10.0) \\\n",
    "    .withColumn(\"date_formatted\", to_date(col(\"DATE\"), \"M/d/yyyy\")) \\\n",
    "    .withColumn(\"month\", month(col(\"date_formatted\"))) \\\n",
    "    .withColumn(\"day_of_year\", dayofyear(col(\"date_formatted\")))\n",
    "features_df = features_df.na.drop(subset=[\"TMAX_actual\", \"Latitude\", \"Longitude\", \"Elevation\", \"month\", \"day_of_year\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44914f8-21e6-43bb-b74a-f2425cea3af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"Latitude\", \"Longitude\", \"Elevation\", \"month\", \"day_of_year\"],\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "assembled_df = assembler.transform(features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1788c533-b096-4789-be77-63a1a03f95fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df = assembled_df.select(col(\"features\"), col(\"TMAX_actual\").alias(\"label\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b81f431-0566-450e-9953-c6c29ab5899c",
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainingData, testData) = model_df.randomSplit([0.8, 0.2], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3b3af7-c41f-424f-a90c-92500bcba41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbt = GBTRegressor(featuresCol=\"features\", labelCol=\"label\", maxIter=10)\n",
    "gbt_model = gbt.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8458b45e-c42b-46ae-bd0e-6f39e5b30417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48452b24-af73-4bd5-8e47-376a4155e053",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, to_date, dayofyear\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import DecisionTreeRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d0af8f1-5f3b-42e3-adae-36cb10d1678e",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"WeatherLinearRegression\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28e6f08e-f3f2-4772-9502-3169e822d6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to CSV in HDFS\n",
    "original_csv_path = \"hdfs://localhost:9000/weather_data//weatherbigdata.csv\"\n",
    "\n",
    "# Step 2: Load and Prepare Data\n",
    "df = spark.read.csv(original_csv_path, header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66569e14-b8ab-4cd3-b070-568ab9135b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = df.na.drop(subset=[\"TMAX\", \"TMIN\"])\n",
    "\n",
    "# Step 2.2: Transform temperature to actual degrees Celsius and add a 'range' column\n",
    "transformed_df = clean_df.withColumn(\"TMAX_actual\", col(\"TMAX\") / 10.0) \\\n",
    "                   .withColumn(\"TMIN_actual\", col(\"TMIN\") / 10.0) \\\n",
    "                   .withColumn(\"TRANGE\", col(\"TMAX_actual\") - col(\"TMIN_actual\"))\n",
    "\n",
    "# Step 2.3: Add a data quality filter to ensure TMAX is greater than or equal to TMIN\n",
    "validated_df = transformed_df.filter(col(\"TMAX_actual\") >= col(\"TMIN_actual\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad9c125b-1d97-442a-b20c-f7b5a1e92acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_df = validated_df.select(\n",
    "    col(\"DATE\"),\n",
    "    col(\"Latitude\").cast(\"double\"),\n",
    "    col(\"Longitude\").cast(\"double\"),\n",
    "    col(\"Elevation\").cast(\"double\"),\n",
    "    col(\"TMAX_actual\").cast(\"double\")\n",
    ").na.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "60a26560-fd1a-459e-a797-151a33019f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+---------+---------+-----------+---------+\n",
      "|      DATE|Latitude|Longitude|Elevation|TMAX_actual|DayOfYear|\n",
      "+----------+--------+---------+---------+-----------+---------+\n",
      "|  3/7/2011| 64.2381|-145.2669|    463.3|       -2.8|       66|\n",
      "| 9/26/2012| 41.9622| -84.9925|    299.9|       20.0|      270|\n",
      "| 12/3/2000|    33.9| -80.5206|     76.2|        3.3|      338|\n",
      "| 5/10/2007| 37.0539| -93.5756|    399.3|       26.7|      130|\n",
      "|  8/2/2018| 45.3614| -84.9511|    228.0|       26.7|      214|\n",
      "| 4/16/2008| 36.5869| -89.5325|     92.0|       15.0|      107|\n",
      "| 7/11/2012| 42.6514|-111.5833|   1780.6|       35.6|      193|\n",
      "|  1/5/1997| 38.3683| -78.2503|    175.9|       23.9|        5|\n",
      "|  2/8/2021| 36.5728|  -79.335|    168.2|       10.6|       39|\n",
      "| 2/19/1998| 44.4419|-100.4172|    506.9|        3.3|       50|\n",
      "| 6/21/2012| 45.4539|-121.1303|    405.4|       31.1|      173|\n",
      "|  7/3/1995| 46.3747|-102.3211|    739.4|       29.4|      184|\n",
      "| 12/1/2002| 38.3794| -81.5911|    278.0|        0.6|      335|\n",
      "|10/17/2001| 41.0731| -71.9236|      2.1|       17.2|      290|\n",
      "| 1/21/2013| 42.5117| -75.5197|    301.4|        6.1|       21|\n",
      "|11/19/1993| 46.0306|-110.5056|   1787.7|        2.8|      323|\n",
      "|  9/6/1996|    43.7|  -109.67|   2667.0|       15.5|      250|\n",
      "|12/14/2004| 37.2008|-113.2686|    973.5|       17.8|      349|\n",
      "|  1/4/1998|   44.16|  -107.13|   2889.5|       -5.0|        4|\n",
      "| 6/23/2009| 47.4389| -97.0664|    277.4|       27.8|      174|\n",
      "+----------+--------+---------+---------+-----------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "featured_df = selected_df.withColumn(\"DayOfYear\", dayofyear(to_date(col(\"DATE\"), \"M/d/yyyy\")))\n",
    "featured_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf7b4495-e6e8-4b29-a3de-309e64b82c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+-----+\n",
      "|features                      |label|\n",
      "+------------------------------+-----+\n",
      "|[64.2381,-145.2669,463.3,66.0]|-2.8 |\n",
      "|[41.9622,-84.9925,299.9,270.0]|20.0 |\n",
      "|[33.9,-80.5206,76.2,338.0]    |3.3  |\n",
      "|[37.0539,-93.5756,399.3,130.0]|26.7 |\n",
      "|[45.3614,-84.9511,228.0,214.0]|26.7 |\n",
      "+------------------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "feature_columns = [\"Latitude\", \"Longitude\", \"Elevation\", \"DayOfYear\"]\n",
    "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
    "\n",
    "final_df = assembler.transform(featured_df).select(\"features\", col(\"TMAX_actual\").alias(\"label\"))\n",
    "\n",
    "final_df.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd15aaf2-b214-4499-81dd-c43b4ae51220",
   "metadata": {},
   "outputs": [],
   "source": [
    "(training_data, test_data) = final_df.randomSplit([0.8, 0.2], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee971f34-b1ab-40f2-b953-0413118de9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeRegressor(featuresCol=\"features\", labelCol=\"label\", maxDepth=10)\n",
    "model = dt.fit(training_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ebc5918-5b8c-4735-bfd6-ea6897610b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------------+\n",
      "|label|        prediction|\n",
      "+-----+------------------+\n",
      "| 26.1|24.783049748825153|\n",
      "| 25.0|24.783049748825153|\n",
      "| 26.1|24.783049748825153|\n",
      "| 26.7|24.588842315369263|\n",
      "| 25.0|26.486188913962792|\n",
      "| 25.6|26.486188913962792|\n",
      "| 27.8| 29.16070818710386|\n",
      "| 27.2| 29.16070818710386|\n",
      "| 26.7|28.079597154023443|\n",
      "| 26.7|28.079597154023443|\n",
      "+-----+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = model.transform(test_data)\n",
    "predictions.select(\"label\", \"prediction\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "93ccfd71-a4ed-44eb-be9c-ad9872ce4b9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree RMSE: 7.037154260163144\n",
      "Decision Tree R2: 0.6867188946792728\n"
     ]
    }
   ],
   "source": [
    "evaluator_rmse = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "evaluator_r2 = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"r2\")\n",
    "\n",
    "rmse = evaluator_rmse.evaluate(predictions)\n",
    "r2 = evaluator_r2.evaluate(predictions)\n",
    "\n",
    "print(f\"Decision Tree RMSE: {rmse}\")\n",
    "print(f\"Decision Tree R2: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b4f13d8a-0be9-4fdf-8f5e-e316e2ae165f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to hdfs://localhost:9000/models/dt_weather_model\n"
     ]
    }
   ],
   "source": [
    "model_path = \"hdfs://localhost:9000/models/dt_weather_model\" # <-- New path\n",
    "model.save(model_path)\n",
    "print(f\"Model saved to {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed85084-3346-4600-bbd0-162246c123b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
